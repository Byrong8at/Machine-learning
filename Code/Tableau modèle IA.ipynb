{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison Modèles IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Modèle**                     | **Avantages**                                                                                     | **Inconvénients**                                                                                       |\n",
    "|---------------------------------|---------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| **Perceptron**                  | - Simple et rapide à entraîner. <br> - Convient pour les problèmes de classification binaire. <br> - Performances bonnes avec des données linéaires. | - Ne fonctionne que pour des données linéaires. <br> - Sensible aux paramètres et nécessite une normalisation des données. <br> - Mauvaise performance sur des relations non linéaires. |\n",
    "| **Logistic Regression**         | - Simple à implémenter et à interpréter. <br> - Bon pour les données linéaires. <br> - Moins sujet au sur-ajustement. <br> - Fournit une probabilité de sortie. | - Inefficace pour des données non linéaires. <br> - Sensible aux variables fortement corrélées. <br> - Pas adapté pour des problèmes complexes. |\n",
    "| **SVM (Support Vector Machine)** | - Efficace pour des marges claires entre classes. <br> - Gère des relations non linéaires avec un noyau. <br> - Bon pour des données de haute dimension. | - Coûteux en calculs. <br> - Sensible au choix des hyperparamètres et du noyau. <br> - Moins interprétable. |\n",
    "| **KNN (K-Nearest Neighbors)**   | - Simple à comprendre et à implémenter. <br> - Pas besoin de phase d'entraînement explicite. <br> - Performant avec des frontières de décision complexes. | - Lent en phase de prédiction, surtout avec de grandes données. <br> - Sensible aux valeurs aberrantes. <br> - Inefficace avec des données de haute dimension. |\n",
    "| **Naive Bayes**                 | - Simple et rapide. <br> - Bon pour des données bruitées. <br> - Performant même avec des données peu corrélées. | - Hypothèse d’indépendance irréaliste. <br> - Mauvais pour les données fortement corrélées. <br> - Moins performant pour des relations complexes. |\n",
    "| **Decision Tree**               | - Facile à comprendre et à interpréter. <br> - Gère bien les relations non linéaires. <br> - Moins sensible aux anomalies. | - Risque de sur-ajustement avec des arbres trop profonds. <br> - Sensible aux petites variations des données. <br> - Moins robuste que Random Forest. |\n",
    "| **Random Forest**               | - Moins susceptible au sur-ajustement. <br> - Très robuste et performant avec des données complexes et bruitées. <br> - Donne l'importance des variables. | - Plus difficile à interpréter. <br> - Plus coûteux en calculs. <br> - Moins efficace sur des petits jeux de données. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
